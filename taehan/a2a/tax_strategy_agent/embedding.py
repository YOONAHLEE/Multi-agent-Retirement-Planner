import pickle
from typing import List, Dict
from langchain.schema import Document
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from config.config import MODEL_CONFIG, EMBEDDING_CONFIG, VECTORSTORE_CONFIG
from langchain_community.vectorstores import OpenSearchVectorSearch
import os

current_path = os.getcwd()
print("í˜„ì¬ ì‘ì—… ê²½ë¡œ:", current_path)

def load_documents(pkl_files: List[str]) -> List[Document]:
    """PKL íŒŒì¼ì—ì„œ ë¬¸ì„œë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    
    Args:
        pkl_files: PKL íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        ë¡œë“œëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
    """
    all_docs = []
    
    for pkl_file in pkl_files:
        # print("ğŸ” ê²½ë¡œ í™•ì¸:", os.path.abspath(pkl_file))
        # print("ì¡´ì¬ ì—¬ë¶€:", os.path.exists(pkl_file))
        with open(pkl_file, 'rb') as f:
            docs = pickle.load(f)
            all_docs.extend(docs)
    
    print(f"ì´ ë¬¸ì„œ ìˆ˜: {len(all_docs)}ê°œ")
    return all_docs

def create_vectorstore(documents: List[Document]) -> FAISS:
    """ë¬¸ì„œë¥¼ ë²¡í„°í™”í•˜ì—¬ FAISS ë²¡í„° ìŠ¤í† ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        documents: ë²¡í„°í™”í•  ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        ìƒì„±ëœ FAISS ë²¡í„° ìŠ¤í† ì–´
    """
    # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
    embeddings = OpenAIEmbeddings(**EMBEDDING_CONFIG)
    
    # FAISS ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
    vectorstore = FAISS.from_documents(documents, embeddings)
    return vectorstore

def create_retrieval_chain(vectorstore: FAISS) -> RetrievalQA:
    """ë²¡í„° ìŠ¤í† ì–´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰ ì²´ì¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        vectorstore: FAISS ë²¡í„° ìŠ¤í† ì–´
        
    Returns:
        ìƒì„±ëœ RetrievalQA ì²´ì¸
    """
    # LLM ì´ˆê¸°í™”
    llm = ChatOpenAI(**MODEL_CONFIG)
    
    # RetrievalQA ì²´ì¸ ìƒì„±
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        retriever=vectorstore.as_retriever()
    )
    
    return qa_chain

def initialize_vectorstores() -> Dict[str, RetrievalQA]:
    """ëª¨ë“  ë²¡í„° ìŠ¤í† ì–´ë¥¼ ì´ˆê¸°í™”í•˜ê³  ê²€ìƒ‰ ì²´ì¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Returns:
        ë²¡í„° ìŠ¤í† ì–´ IDë¥¼ í‚¤ë¡œ í•˜ëŠ” RetrievalQA ì²´ì¸ ë”•ì…”ë„ˆë¦¬
    """
    qa_chains = {}
    
    for store_id, config in VECTORSTORE_CONFIG.items():
        # ë¬¸ì„œ ë¡œë“œ
        documents = load_documents(config["pkl_files"])
        
        # ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
        vectorstore = create_vectorstore(documents)
        
        # ê²€ìƒ‰ ì²´ì¸ ìƒì„±
        qa_chain = create_retrieval_chain(vectorstore)
        
        qa_chains[store_id] = qa_chain
    
    return qa_chains

def save_vectorstore(vectorstore: FAISS, path: str):
    """ë²¡í„° ìŠ¤í† ì–´ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        vectorstore: ì €ì¥í•  FAISS ë²¡í„° ìŠ¤í† ì–´
        path: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
    """
    vectorstore.save_local(path)

def load_vectorstore(path: str, embedding_model: str = "text-embedding-3-small") -> FAISS:
    """ì €ì¥ëœ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    
    Args:
        path: ë²¡í„° ìŠ¤í† ì–´ íŒŒì¼ ê²½ë¡œ
        embedding_model: ì‚¬ìš©í•  ì„ë² ë”© ëª¨ë¸
        
    Returns:
        ë¡œë“œëœ FAISS ë²¡í„° ìŠ¤í† ì–´
    """
    # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
    embeddings = OpenAIEmbeddings(
        model=embedding_model,
        openai_api_key=MODEL_CONFIG["openai_api_key"]
    )
    
    # ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ
    vectorstore = FAISS.load_local(path, embeddings)
    return vectorstore 