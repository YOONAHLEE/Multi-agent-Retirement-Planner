import pickle
import os
import glob
from pathlib import Path
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from langchain_core.tools.retriever import create_retriever_tool
from config.config import MODEL_CONFIG, EMBEDDING_CONFIG, VECTORSTORE_CONFIG
from typing import List, Dict
from langchain.schema import Document
from langchain_teddynote.retrievers import KiwiBM25Retriever
from langchain.retrievers import EnsembleRetriever
from langchain_core.tools import BaseTool

def load_documents_from_pkl(filepath):
    """
    Pickle íŒŒì¼ì—ì„œ Langchain Document ë¦¬ìŠ¤íŠ¸ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” í•¨ìˆ˜

    Args:
        filepath: ì›ë³¸ íŒŒì¼ ê²½ë¡œ (ì˜ˆ: path/to/filename.pdf)
    Returns:
        Langchain Document ê°ì²´ ë¦¬ìŠ¤íŠ¸
    """
    # í™•ì¥ì ì œê±°í•˜ê³  ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
    abs_path = os.path.abspath(filepath)
    base_path = os.path.splitext(abs_path)[0]
    pkl_path = f"{base_path}.pkl"

    with open(pkl_path, "rb") as f:
        documents = pickle.load(f)
    return documents

def load_documents_from_dir(dir_path):
    """
    ì§€ì •ëœ ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë“  .pkl íŒŒì¼ì„ ì°¾ì•„ì„œ Langchain Document ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜

    Args:
        dir_path: ë””ë ‰í† ë¦¬ ê²½ë¡œ
    Returns:
        Langchain Document ê°ì²´ ë¦¬ìŠ¤íŠ¸
    """
    # extract_path ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë“  .pkl íŒŒì¼ ì°¾ê¸°
    extract_path = dir_path
    pkl_files = glob.glob(str(Path(extract_path) / "**" / "*.pkl"), recursive=True)

    if not pkl_files:
        print("âŒ extract_pathì—ì„œ .pkl íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # ëª¨ë“  .pkl íŒŒì¼ì—ì„œ ë¬¸ì„œ ë¡œë“œ
        all_documents = []
        for pkl_file in pkl_files:
            print(f"ğŸ“„ {pkl_file} íŒŒì¼ ë¡œë“œ ì¤‘...")  # í•œêµ­ì–´ ì½”ë©˜íŠ¸
            documents = load_documents_from_pkl(pkl_file)
            all_documents.extend(documents)

        print(f"âœ… ì´ {len(all_documents)}ê°œì˜ ë¬¸ì„œê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
        return all_documents
    return []

def create_vectorstore(documents: List[Document]) -> FAISS:
    """ë¬¸ì„œë¥¼ ë²¡í„°í™”í•˜ì—¬ FAISS ë²¡í„° ìŠ¤í† ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        documents: ë²¡í„°í™”í•  ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        ìƒì„±ëœ FAISS ë²¡í„° ìŠ¤í† ì–´
    """
    # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
    embeddings = OpenAIEmbeddings(**EMBEDDING_CONFIG)
    
    # FAISS ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
    vectorstore = FAISS.from_documents(documents, embeddings)
    return vectorstore

def initialize_retriever_tool() -> List[BaseTool]:
    """FAISS ë²¡í„° ìŠ¤í† ì–´ë¥¼ ì´ˆê¸°í™”í•˜ê³  ë¦¬íŠ¸ë¦¬ë²„ íˆ´ì„ ìƒì„±í•©ë‹ˆë‹¤.
    Returns:
        ë¦¬íŠ¸ë¦¬ë²„ íˆ´ ë¦¬ìŠ¤íŠ¸
    """
    # bm25 retrieverì™€ semantic retrieverì˜ íŒŒë¼ë¯¸í„° ì„¤ì •
    vectorstore_path = VECTORSTORE_CONFIG["path"]

    bm25_k = VECTORSTORE_CONFIG["bm25_k"]
    semantic_k = VECTORSTORE_CONFIG["semantic_k"]
    bm25_weight = VECTORSTORE_CONFIG["bm25_weight"]
    semantic_weight = VECTORSTORE_CONFIG["semantic_weight"]

    # ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ
    documents = load_documents_from_dir(vectorstore_path)
    vector = create_vectorstore(documents)

    docs = vector.docstore._dict.values()
    texts = [doc.page_content for doc in docs]

    # í‚¤ì›Œë“œ ì„œì¹˜
    bm25_retriever = KiwiBM25Retriever.from_texts(texts)
    bm25_retriever.k = bm25_k 

    # ì‹œë©˜í‹± ì„œì¹˜
    semantic_retriever = vector.as_retriever( search_kwargs={"k": semantic_k} )

    # ì•™ìƒë¸” ë¦¬íŠ¸ë¦¬ë²„ ìƒì„±
    ensemble_retriever = EnsembleRetriever(
        retrievers=[bm25_retriever, semantic_retriever],
        weights=[bm25_weight, semantic_weight],  # ê° ë¦¬íŠ¸ë¦¬ë²„ì˜ ê°€ì¤‘ì¹˜ ì„¤ì •
        search_kwargs={"k": bm25_k + semantic_k},  # ìµœì¢… ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜
    )

    # ë¦¬íŠ¸ë¦¬ë²„ íˆ´ ìƒì„±
    retriever_tool = create_retriever_tool(
        ensemble_retriever,
        name="pdf_search",  # ë„êµ¬ì˜ ì´ë¦„ì„ ì…ë ¥í•©ë‹ˆë‹¤.
        description="use this tool to search financial information from the PDF document",  # ë„êµ¬ì— ëŒ€í•œ ì„¤ëª…ì„ ìì„¸íˆ ê¸°ì…í•´ì•¼ í•©ë‹ˆë‹¤!!
    )

    return retriever_tool

def save_vectorstore(vectorstore: FAISS, path: str):
    """ë²¡í„° ìŠ¤í† ì–´ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        vectorstore: ì €ì¥í•  FAISS ë²¡í„° ìŠ¤í† ì–´
        path: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
    """
    vectorstore.save_local(path)

def load_vectorstore(path: str, embedding_model: str = "text-embedding-3-small") -> FAISS:
    """ì €ì¥ëœ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    
    Args:
        path: ë²¡í„° ìŠ¤í† ì–´ íŒŒì¼ ê²½ë¡œ
        embedding_model: ì‚¬ìš©í•  ì„ë² ë”© ëª¨ë¸
        
    Returns:
        ë¡œë“œëœ FAISS ë²¡í„° ìŠ¤í† ì–´
    """
    # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
    embeddings = OpenAIEmbeddings(
        model=embedding_model,
        openai_api_key=MODEL_CONFIG["openai_api_key"]
    )
    
    # ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ
    vectorstore = FAISS.load_local(path, embeddings)
    return vectorstore 